# 目标检测

## 综述

近几年来，目标检测算法取得了很大的突破。比较流行的算法可以分为两类，一类是基于Region Proposal的R-CNN系算法（R-CNN，Fast R-CNN, Faster R-CNN等），它们是two-stage的，需要先算法产生目标候选框，也就是目标位置，然后再对候选框做分类与回归。而另一类是Yolo，SSD这类one-stage算法，其仅仅使用一个卷积神经网络CNN直接预测不同目标的类别与位置。第一类方法是准确度高一些，但是速度慢，但是第二类算法是速度快，但是准确性要低一些

## 常用算法

### R-CNN
目标检测有两个主要任务：**物体分类和定位**，为了完成这两个任务，R-CNN借鉴了滑动窗口思想， 采用对区域进行识别的方案，具体是：

1. 输入一张图片，通过指定算法从图片中提取 2000 个类别独立的候选区域（可能目标区域）**——提取候选区域**
2. 对于每个候选区域利用卷积神经网络来获取一个特征向量**——提取特征向量**
3. 对于每个区域相应的特征向量，利用支持向量机SVM 进行分类，并通过一个bounding box regression调整目标包围框的大小**——分类**
4. ——**边框修正**

**R-CNN的贡献，可以主要分为两个方面：**

1. 使用了<u>卷积神经网络进行特征提取</u>
2. 使用<u>bounding box regression进行目标包围框的修正</u> 

**R-CNN有什么问题：**

1. 耗时的selective search，对一张图像，需要花费2s
2. 耗时的串行式CNN前向传播，对于每一个候选框，都需经过一个AlexNet提取特征，为所有的候选框提取特征大约花费47s
3. 三个模块（CNN特征提取、SVM分类和边框修正）是分别训练的，并且在训练的时候，对于**存储空间的消耗很大**

### Fast R-CNN

面对R-CNN的缺陷，Ross在2015年提出的Fast R-CNN进行了改进

1. 首先还是采用selective search提取2000个候选框RoI
2. 使用一个卷积神经网络对全图进行特征提取
3. 使用一个RoI Pooling Layer在全图特征上摘取每一个RoI对应的特征
4. 分别经过为21和84维的全连接层（并列的，前者是分类输出，后者是回归输出）
   Fast R-CNN通过CNN直接获取整张图像的特征图，再使用RoI Pooling Layer在特征图上获取对应每个候选框的特征，避免了R-CNN中的对每个候选框串行进行卷积（耗时较长）。

### Faster R-CNN

<u>Faster R-CNN 取代selective search</u>，直接通过一个<u>Region Proposal Network (RPN)</u>生成待检测区域，这么做，在生成RoI区域的时候，时间也就从2s缩减到了10ms

**Faster R-CNN由<u>共享卷积层、RPN、RoI pooling以及分类和回归</u>四部分组成：**

1. 使用共享卷积层为全图<u>提取特征</u>feature maps
2. 将得到的feature maps送入RPN，<u>RPN生成待检测框</u>(指定RoI的位置),并对RoI的包围框进行第一次修正
3. RoI Pooling Layer根据RPN的输出在feature map上面选取每个RoI对应的特征，并将维度置为定值
4. <u>使用全连接层(FC Layer)对框进行分类</u>，并且进行目标包围框的第二次修正。尤其注意的是，Faster R-CNN真正实现了端到端的训练(end-to-end training)。Faster R-CNN最大特色是使用了RPN取代了SS算法来获RoI，以下对RPN进行分析。

**RPN——用于生成检测框**
经典的检测方法生成检测框都非常耗时，如<u>OpenCV adaboost</u>使用<u>滑动窗口+图像金字塔</u>生成检测框；或如<u>R-CNN</u>使用<u>SS(Selective Search)</u>方法生成检测框。而<u>Faster R-CNN</u>则抛弃了传统的滑动窗口和SS方法，直接使用<u>RPN</u>生成检测框，这也是Faster R-CNN的巨大优势，能极大提升检测框的生成速度。

**anchor**
简单地说，RPN依靠一个在共享特征图上滑动的窗口，为每个位置生成9种**预先设置**好长宽比与面积的目标框(即anchor)。<u>其实RPN最终就是在原图尺度上，设置了密密麻麻的候选anchor。进而去判断anchor到底是前景还是背景，意思就是判断这个anchor到底有没有覆盖目标，以及为属于前景的anchor进行第一次坐标修正。</u>

### Mask R-CNN

Mask R-CNN可以分解为如下的3个模块：<u>Faster-RCNN、RoI Align和Mask</u>

**ROI Align**

Mask R-CNN使用RoI Align取代了Faster RCNN中的RoI Pooling

### Yolo
以上目标检测模型都是<u>two-stage算法</u>，针对于two-stage目标检测算法普遍存在的<u>运算速度慢</u>的缺点，Yolo创造性的提出了<u>one-stage</u>，也就是<u>将物体分类和物体定位在一个步骤中完成</u>。Yolo直接在输出层回归bounding box的位置和bounding box所属类别，从而实现one-stage。通过这种方式，Yolo可实现45帧每秒的运算速度，完全能满足实时性要求（达到24帧每秒，人眼就认为是连续的）

<u>主要分为三个部分：卷积层，目标检测层，NMS筛选层</u>

**卷积层——用于特征提取**

**NMS筛选层**
筛选层是为了在多个结果中（多个bounding box）筛选出最合适的几个，这个方法和faster R-CNN 中基本相同

**Yolo损失函数**
yolo的损失函数包含三部分，<u>位置误差，confidence误差，分类误差</u>

### SSD
Faster R-CNN<u>准确率mAP</u>较高，<u>漏检率</u><u>recall</u>较低，但速度较慢。而Yolo则相反，速度快，但准确率和漏检率不尽人意。SSD综合了他们的优缺点。

<u>组成部分：卷积层，目标检测层和NMS筛选层</u>

 **为什么SSD对小目标检测效果不好：**

- 小目标对应的anchor比较少，其对应的feature map上的pixel难以得到训练，这也是为什么SSD在augmentation之后精确度上涨（因为crop之后小目标就变为大目标）
- 要检测小目标需要足够大的feature map来提供精确特征，同时也需要足够的语义信息来与背景作区分

-------------------------------------------------------- **至此参考连接：**[CSDN](https://blog.csdn.net/electech6/article/details/95240278)---------------------------------------------------------

